# 운영체제

<details>
    <summary style="font-size : 20px;"><strong> Q. 운영 체제란 무엇입니까?</strong></summary></br>
    
운영체제란 하드웨어와 응용 프로그램 사이에서 인터페이스 역할을 하고 시스템의 자원과 동작을 관리하는 시스템 소프트웨어입니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. 운영체제의 역할은 무엇인가요?</strong></summary></br>
    
운영체제의 역할은 프로세스, 저장장치, 네트워킹, 사용자 계정, 디바이스 드라이버를 관리합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. 운영체제에서 커널(kernel)은 무엇인가요?</strong></summary></br>
    
커널(kernel)은 컴퓨터의 운영 체제의 핵심이 되는 컴퓨터 프로그램의 하나로, 시스템의 모든 것을 통제합니다. 커널은 메모리 관리, 프로세스 관리, 장치 드라이버 관리, 시스템 호출 및 보안을 담당합니다. 메모리 관리는 메모리가 어디에서 무엇을 저장하는 데 얼마나 사용되는지를 추적합니다. 프로세스 관리는 어느 프로세스가 CPU를 언제 얼마나 오랫동안 사용할지를 결정합니다. 장치 드라이버 관리는  하드웨어와 프로세스 사이에서 중재자/인터프리터의 역할을 수행합니다. 시스템 호출 및 보안은 프로세스의 서비스 요청을 수신합니다.   
</details></br>


<details>
    <summary style="font-size : 20px;"><strong> Q. 시스템 콜은 무엇인가요?</strong></summary></br>
    
운영체제는 커널 모드와 사용자 모드로 나뉘는데, 시스템 콜은 사용자 모드에서 커널 모드를 사용할 수 있게 해줍니다. 다시 말해서 시스템 콜은 응용프로그램에서 커널의 기능을 사용할 수 있게 해줍니다. 시스템 콜의 유형에는 프로세스 제어, 파일 제어, 디바이스 제어, 정보 관리, 통신등이 있습니다. 프로그래밍 언어에서 시스템 콜을 호출하면 커널 모드로 전환되고, 커널에서 작업이 완료되면 다시 사용자 모드로 전환됩니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. 동기와 비동기의 차이는 무엇인가요?</strong></summary></br>
    
동기(sync)방식은 호출하는 함수의 작업이 종료될 때까지 기다린 뒤 다음 로직을 실행하는 방식입니다. 여러 요청을 동시에 처리할 순 없지만 설계가 직관적이고 간단합니다.   
비동기(async)방식은 호출하는 함수의 작업 완료 여부와 상관없이 다음 로직이 실행됩니다. 여러 요청을 동시에 처리할 수 있지만 설계가 비교적 복잡합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. Blocking과 Non-Blocking 방식의 차이는 무엇인가요?</strong></summary></br>
    
blocking은 호출된 함수가 자신의 작업이 모두 끝낼 때까지 제어권을 가지고 있어 호출한 함수가 대기하도록 만듭니다. 
non-blocking은 호출된 함수가 바로 return하며 호출한 함수에게 제어권을 줍니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>   Q. 프로세스 메모리 영역 구조에 대해서 말해주세요.</strong></summary></br>
    
프로세스의 메모리 영역은 코드, 데이터, 힙, 스택 영역으로 나뉩니다. 코드 영역은 프로그램을 실행하는데 필요한 코드가 담긴 영역이고 데이터 영역은 전역 변수, 정적 변수가 저장되는 영역입니다. 힙 영역은 사용자가 동적으로 메모리를 할당하고 해제할 수 있는 영역으로 런타임시 크기가 결정됩니다. 힙 영역의 메모리는 낮은 주소에서 높은 주소 방향으로 할당됩니다. 스택 영역은 매개 변수, 지역 변수, 리턴 값등이 담기는 영역으로 컴파일시 크기가 결정됩니다. 스택 영역의 메모리는 높은 주소에서 낮은 주소로 할당됩니다. 각 프로세스는 독립된 메모리 영역을 가집니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>   Q. 프로세스와 스레드의 차이는 무엇인가요?</strong></summary></br>
    
프로세스는 실행중인 프로그램으로 운영체제로부터 자원을 할당받아 독립된 메모리영역을 가집니다. 스레드는 프로세스 내부에서 실행되는 작업의 단위로서 프로세스의 메모리중 스택 영역을 제외한 나머지를 공유합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>   Q. 멀티 프로세스 vs 멀티 스레드를 비교해주세요.</strong></summary></br>
    
멀티 프로세스는 작업을 여러 프로세스로 분리한 것으로 각 프로세스는 독립된 메모리 영역을 가지고 있습니다. 멀티 스레드는 프로세스 내부에서 작업을 여러 개의 스레드로 처리하는 것으로 스택 영역을 제외하고 자원을 공유합니다. 스레드간 Context switching 발생시 stack영역만 변경하면 되기 때문에 상대적으로 오버헤드가 적지만, 프로세스간 Context switching 발생시 캐시, 메모리 매핑 초기화 작업들이 모두 이뤄져 상대적으로 오버헤드가 큽니다. 멀티스레드는 자원을 공유하는 특성으로 인해 동기화 문제가 발생할 수 있고 다른 스레드에게 영향을 줄 수 있습니다. 반면, 멀티프로세스는 독립적인 메모리 영역을 갖기 때문에 하나의 프로세스가 비정상적으로 종료되도 다른 프로세스가 영향을 받지 않습니다. 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. 인터럽트란 무엇인가요?</strong></summary></br>
    
CPU가 프로그램을 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생하여 처리가 필요할 경우에 마이크로프로세서에게 알려 처리할 수 있도록 하는 것을 말합니다. 인터럽트는 크게 하드웨어 인터럽트와 소프트웨어 인터럽트로 나뉩니다.
  
**하드웨어 인터럽트**  
하드웨어가 발생시키는 인터럽트로, CPU가 아닌 다른 하드웨어 장치가 CPU에게 어떤 사실을 알려주거나 CPU 서비스를 요청해야할 경우 발생합니다.

**소프트웨어 인터럽트**
소프트웨어 인터럽트는 예외 상황이나 system call등의 이유로 발생하며 소프트웨어가 스스로 인터럽트 라인을 설정합니다.

**인터럽트 핸들러** : 인터럽트 핸들러는 실제 인터럽트를 처리하기위한 루틴으로 인터럽트 서비스 루틴이라고도 불립니다. 운영체제의 코드 영역에는 인터럽트별로 처리해야할 내용이 이미 프로그래밍되어 있습니다.  
**인터럽트 백터** : 인터럽트 발생시 처리해야할 인터럽트 핸들러의 주소를 인터럽트 별로 보관하고있는 테이블

</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. 인터럽트의 처리과정은 어떻게 이뤄지나요? </strong></summary></br>

프로그램이 실행중 인터럽트가 발생하면 현재 실행하던 프로그램을 멈추고 program counter와 상태 레지스터를 스택에 저장합니다. 인터럽트 벡터에서 인터럽트 서비스 루틴의 주소값을 읽어 이동하고
 인터럽트 서비스 루틴이 끝나면 다시 돌아와 저장된 내용을 복원하고 다시 프로그램을 실행합니다.

</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. Context Switching이란?</strong></summary></br>
    
어떤 프로세스가 CPU에서 작업중일 때 다른 프로세스가 CPU를 사용하기 위해 작업중인 내용을 PCB에 저장하고 새로운 프로세스를 CPU로 적재하는 것을 말합니다. 적재된 프로세스는 프로그램 카운터에서 이어서 작업할 주소를 복구하여 작업을 진행합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. 프로세스의 상태 변화를 설명하시오</strong></summary></br>
    
커널에 작업이 등록되면 pcb가 할당되고 프로세스는 new상태로 만들어 집니다. New 상태의 프로세스는 메모리에 적재되면서 ready상태로 전이됩니다. Ready 상태의 프로세스는 cpu 스케쥴링으로 cpu를 할당받게 되면 running 상태로 전이됩니다. Running상태에서 인터럽트가 발생하면 다시 ready상태가 되고, I/O 요청이나 기타 이벤트 발생하면 wating상태로 전이됩니다. IO/기타 이벤트 작업이 종료되면 waiting상태에서 ready 상태로 전이됩니다. 프로세스의 작업이 완료되면 자원을 반납하고 terminated상태로 전이됩니다. 스케쥴링에 따라 ready, waiting 상태의 프로세스는 swap device로 swap out될 수 있습니다. 이런 경우 suspended ready, suspended waiting상태로 전이됩니다. 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. IPC에 대해서 설명하시오</strong></summary></br>
    
IPC는 프로세스 간 통신위한 기법으로 pipe, message queue, shared memory, socket같은 방법이 있습니다.

1. 익명의 pipe  
동일한 ppid(부모 프로세스 id)를 갖는 프로세스간 단방향 통신을 지원합니다. 양쪽 모두 송수신이 가능한 구조를 만들기 위해서는 pipe를 두 개 만들어야합니다. FIFO방식으로 동작하며 주로 부모와 자식 프로세스간 통신에 사용됩니다.

2. named pipe  
이름을 가진 pipe를 사용해서 서로 다른 프로세스간 pipe의 이름만 알면 통신이 가능합니다. FIFO구조이며 단방향 통신으로 주로 연관이 없는 프로세스간 통신에 사용됩니다.

3. message queue  
queue를 사용하여 메모리에서 데이터가 관리되는 구조입니다. 메세지 큐는 커널에서 전역적으로 관리되고 모든 프로세스에서 접근이 가능하므로 데이터 공유가 가능합니다.  

4. shared memory  
커널에서 관리하는 메모리를 서로 다른 프로세스간에 공유하여 사용합니다. 공유 메모리에서 데이터를 공유하므로 다수의 프로세스에게 정보를 공유하는데 용이한 특징이 있지만 공유 메모리 공간에 대한 접근 제어가 필요합니다.

</details></br>

## 프로세스 스케쥴링

<details>
    <summary style="font-size : 20px;"><strong> Q. 프로세스 스케쥴링 (long term, short term, medium term)의 차이를 설명하시오</strong></summary></br>
    
Long term 스케쥴링은 메모리와 디스크 사이에 스케쥴링을 담당합니다. 한정된 메모리에 많은 프로세스가 한번에 올라오는 경우 프로세스는 임시로 디스크에 저장됩니다. Long term 스케쥴링은 디스크에 있는 프로세스를 메모리에 적재하는 역할을 합니다. 프로세스를 new -> ready상태로 전이시킵니다.

Medium term 스케쥴링은 메모리에 올라간 프로세스 수를 조절하기위해 메모리 상의 프로세스를 통째로 swap device로 쫒아내는 swap out을 합니다. 프로세스에게 메모리를 deallocate하며 프로세스의 상태를 suspended로 전이시킵니다. swap out되는 프로세스는 ready, waiting상태이며 ready상태보단 waiting상태가 당장 cpu를 할당받을 가능성이 낮기 때문에 우선적으로 swap out됩니다. 

Short term 스케쥴링은 cpu 스케쥴링이라고도 불리며 ready상태의 프로세스에게 cpu를 할당하는 작업을 합니다. 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>Q. CPU 스케쥴링이란?</strong></summary></br>
    
Ready queue에 들어있는 프로세스중 어떤 프로세스에게 cpu를 할당할지 결정하는 작업을 말합니다. CPU 스케쥴링 방식에는 선점, 비선점 방식 있습니다. 비선점 방식은 cpu burst가 끝날 때 까지 context switching이 발생하지 않고 대기하는 것을 말하고, 선점 방식은 cpu burst가 끝나지 않더라도 context switching이 발생하는 방식을 말합니다. cpu 스케쥴링의 대상이되어 cpu를 할당 받게되면 프로세스 상태가 ready -> running 상태로 전이됩니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>Q. CPU 스케쥴링은 언제 발생하나요?</strong></summary></br>
    
인터럽트 발생으로 running -> ready상태로 전이될 때,
I/O작업 및 다른 이벤트 발생으로 running -> waiting 상태로 전이될 때, 
I/O작업 및 다른 이벤트 작업 완료로 waiting -> ready 상태로 전이될 때,
프로세스가 종료 될 때 발생합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>Q. CPU 스케쥴링 기법들을 설명하시오</strong></summary></br>
    
FCFS(first come first served) : 먼저온 순서대로 처리하는 방식으로 구현이 간단합니다. 비선점형으로서 CPU burst가 완료될 때까지 CPU를 반환하지 않습니다. 소요시간이 긴 프로세스가 먼저 도착하면 짧은 프로세스는 대기시간이 길어지는 convoy effect가 발생합니다.   

Round Robin : 일정 time slice를 기준으로 ready queue의 담긴 프로세스를 돌아가며 실행하는 선점 방식입니다. time slice가 경과하면 ready queue의 끝에 추가되고 다음 프로세스가 CPU를 할당받습니다. time slice가 길수록 FCFS방식과 유사하고 짧을수록 모든 프로세스가 동시에 작업하는 것처럼 보이지만 context switching에 대한 오버헤드가 커집니다.    

Priority Scheduling : 우선순위가 가장 높은 프로세스에게 CPU를 할당하는 방식입니다. 선점형과 비선점형 둘 다 가능하며 비선점형은 더 높은 우선순위의 프로세스가 오면 ready queue의 head에 추가됩니다. 우선 순위가 낮은 프로세스는 차례가 오지 않는 starvation 문제가 발생할 수 있는데 aging기법으로 시간이 지남에 따라 우선순위를 높여주는 방식을 적용할 수 있습니다.  

SJF(shortest job first) : CPU burst time이 짧은 프로세스에게 CPU를 할당합니다. 비선점형으로 더 짧은 CPU burst time을 갖는 프로세스가 오면 ready queue의 head에 추가됩니다. 시스템의 프로세스를 최소화하여 스케쥴링의 부하가 감소하고 메모리를 절약해 시스템 효율을 높이지만 CPU burst time이 길면 순서가 오지 않는 starvation문제가 존재하고 CPU burst time을 예측해야한다는 어려움이 있습니다.

SRT(shortest remaining time) : 잔여 실행시간이 짧은 프로세스에게 CPU를 할당합니다. 선점형으로 잔여 실행시간이 더 짧은 프로세스가 오면 CPU를 반납합니다. 주어진 집합에대해 최소 평균 대기시간을 제공하지만 여전히 starvation문제와 잔여 실행 시간을 예측해야한다는 문제점이 있습니다.

HRRN(highest respone ratio next) : SJF의 단점인 긴 작업과 짧은 작업의 불평등을 보완한 방식으로 대기 시간이 길어질수록 우선 순위가 높아집니다. starvation을 방지할 수 있지만 cpu burst time을 예측해야하는 문제가 있습니다.

MLQ(multi level queue): ready queue를 여러개로 분리하고 큐 사이에도 우선순위를 부여하는 방식입니다. 각 queue는 우선순위를 가지며 프로세스는 최초에 배정된 queue를 벗어나지 못합니다. 선점형 스케쥴링 방식으로 여러개의 queue를 관리해야하는 overhead와 우선 순위에 따른 starvation 문제가 존재합니다.

MFQ(multi level feedback queue) :  ready queue를 여러개로 분리하고 큐 사이에도 우선순위를 부여하는 방식으로 프로세스는 최초에 배정된 queue를 벗어날 수 있습니다. IO bounded process는 높은 우선순위를 가지고 cpu bounded process는 낮은 우선순위를 가집니다. 우선 순위가 높은 큐일수록 짧은 time slice를 주고 time slice내에 작업이 끝나면 한단계 낮은 큐로 내려 보냅니다. 반대로 어떤 큐에서 일정시간내에 작업이 실행되지 못하면 한단계 높은 큐로 프로세스를 이동시킵니다. 이를 통해 starvation문제를 해결할 수 있습니다. 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>Q. Starvation 현상은 무엇인가요?</strong></summary></br>
    
낮은 우선순위로 프로세스가 자원을 할당받지 못하는 현상입니다. aging기법으로 시간이 지남에 따라 우선 순위를 높여주며 해결할 수 있습니다.
</details></br>

## 프로세스 동기화
<details>
    <summary style="font-size : 20px;"><strong> Q. Critical section이란?</strong></summary></br>
    
어떤 공유자원에 대해 동시에 접근하는 작업이 실행되는 영역. Critical section 문제를 해결하기 위해서는 어떤 프로세스가 critical section에서 작업중이라면 다른 프로세스는 접근하지 못하도록 하는 mutual exclusion, critical section에서 작업중인 프로세스가 없다면 대기중인 프로세스는 critical section에 진입하도록 하는 progress, 대기하는 프로세스에 대하여 무한정 대기하는게 아닌 제한된 대기하는 bounded wait조건을 만족해야 합니다.
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. 프로세스 동기화란?</strong></summary></br>
    
공유 자원에 대하여 동시에 사용하지 못하도록 실행을 제어하는 기법
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. Mutual exclusion이란?</strong></summary></br>
    
특정 공유 자원을 한 순간에 하나의 프로세스만 사용할 수 있을 때, 어떤 프로세스가 공유 자원에 접근하는 동안 다른 프로세스가 해당 자원에 접근할 수 없게 하는 것
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. Spin lock과 semaphore의 차이는 무엇인가요?</strong></summary></br>
    
spin lock은 하나의 프로세스가 critical section에 진입할 때 lock을 소유합니다. lock이 없다면 busy waiting 방식으로 loop를 돌면서 lock 반환될 때까지 대기합니다. lock을 소유한 프로세스는 critical section을 빠져나오면서 lock을 반환합니다.  

semaphore는 spin lock과 유사하게 lock을 소유하고 반납하지만 ready queue를 사용해 진입 대기중인 프로세스를 관리한다는 차이점이 있습니다. 이로인해 busy waiting이 발생하지않고 lock을 반납할 때 ready queue에 대기중인 프로세스를 깨우는 방식으로 이뤄집니다. 
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. 뮤텍스와 세마포어의 차이는?</strong></summary></br>
    
뮤텍스는 세마포어의 일종입니다. binary semaphore를 뮤텍스라고 지칭합니다. 즉 0과 1의 상태를 가지므로 오직 1개의 프로세스만이 critical section에 접근할 수 있습니다. 반면, 세마포어는 binary semaphore뿐만 아니라 여러 상태를 가지는 counting semaphore도 존재합니다. 카운팅 세마포어는 가용한 자원의 개수로 초기화되며 자원을 사용하면 세마포어가 감소, 반납하면 세마포어가 증가합니다. 세마포어의 변수만큼 프로세스가 접근할 수 있습니다. 이렇기에 뮤텍스는 lock을 소유한 프로세스가 lock을 반납해야하지만 세마포어의 경우 다른 프로세스가 lock을 반납할수도 있습니다.   
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>   Q. eventcount/sequencer이란? 동작 원리는?</strong></summary></br>

세마포어는 ready queue에 어떤 프로세스를 깨울지 비결정적입니다. 즉, 기아 상태가 발생할 수 있다는 것인데, 이벤트 카운트와 시퀸서는 이 문제를 해결하기위해 사용될 수 있습니다. eventcount는 정수형 변수로 특정 사건의 발생 횟수를 기록합니다. 시퀸서는 정수형 변수로 생성시 0으로 초기화되고 오직 값이 증가하는 연산만을 가집니다. 프로세스가 critical section에 접근하면 sequencer가 증가합니다. 만약, eventcount보다 squencer가 작거나 같다면 critical section으로 진입합니다. 반대의 경우는 ready queue로 이동합니다. 프로세스의 작업이 끝나면 eventcount를 증가시키고 다음 차례의 프로세스를 깨웁니다.   
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>Q. 모니터란? 동작 원리는?</strong></summary></br>

모니터는 high level 메카니즘으로 language level에서 컨트롤 합니다. monitor는 공유 데이터와 critical section의 집합으로서 사용이 쉽기 때문에 deadlock등 error발생 가능성이 낮습니다. 다만, 지원하는 언어에서만 사용이 가능하고 OS가 컴파일러를 이해하고 있어야 critical section접근을 위한 코드를 생성합니다. 구조적인 특징은 entry queue와  signaler queue, condition queue가 존재합니다. 모니터에는 하나의 프로세스만이 진입이 가능합니다. 먼저 도착한 프로세스가 모니터로 들어가 공유 자원을 가지고 나오면 다른 프로세스가 모니터로 들어갑니다. 공유 자원이 없기 때문에 condition queue이동해서 대기하고 있습니다. 작업을 끝낸 프로세스는 모니터로 다시 들어와 공유 자원을 반납하고 signaler queue로 이동합니다. 그리고 condition queue에서 대기중인 프로세스를 깨우면 그 프로세스는 모니터에 들어가 공유 자원을 가지고 나갑니다. signaler queue에 있던 프로세스는 다시 모니터로 들어가 잔여 작업이 있다면 실행하는 방식으로 이뤄집니다.   
 
</details></br>

## 데드락
<details>
    <summary style="font-size : 20px;"><strong>Q. 데드락이란 무엇인가요? </strong></summary></br>

데드락이란 발생 가능성이 없는 이벤트를 기다리는 상태를 말합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>Q. 데드락의 발생 조건? </strong></summary></br>

데드락은 4가지의 조건이 모두 충족되어야 발생합니다.  
첫번째, exclusive한 자원에 대해 여러 프로세스가 동시에 사용하려는 경우 (mutual exclusion)  
두번째, 비선점의 특성을 지닌 자원 (no preemption)  
세번째, 자원을 소유하고 있으면서 다른 자원을 요청 (hold and wait)   
네번째, 프로세스간 자원을 요청하는 형태가 원을 이룸  (circular wait)
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. 데드락을 해결 하는 방법은?  </strong></summary></br>

데드락의 해결 방법에는 예방, 회피, 탐지 3가지가 있습니다.    
**Prevention**  
deadlock prevention은 데드락이 성립하는 4가지 요건중 하나를 제거하므로서 데드락을 예방합니다.
첫 번째로 모든 자원 공유를 허용할 수 있습니다. 하지만 동시에 자원을 사용하므로서 동기화 문제가 발생합니다. 
두 번째는 모든 자원에 대해 선점을 허용할 수 있습니다. 프로세스가 할당 받을 수 없는 자원을 요청한 경우 기존에 가지고 있던 자원을 반납하고 작업을 취소해야합니다.
세 번째는 필요한 자원을 한번에 모두 할당하는 방법입니다. 이 방식은 독점으로 인해 필요하지 않는 순간에도 자원을 소유해 자원 낭비가 발생합니다.
네 번째는 circular wait조건을 제거하는 것입니다. 자원들에게 순서를 부여하여 프로세스는 순서의 증가 방향으로만 자원 요청을 가능하게 합니다. 이렇게 하면 순서에 맞지않는 자원을 할당받을 수 없어 데드락이 발생하지 않습니다. 하지만 자원이 있음에도 순서로 인해 작업이 진행되지 않는 상황이 발생할 수 있습니다.

prevention은 자원의 효율성을 떨어트리고 비용이 많이드는 방법입니다. 또한, 다른 문제를 야기할 수 있습니다.   

**Avoidance**  
deadlock avoidance는 시스템의 상태를 계속 감시하면서 deadlock 상태가 될 가능성이 있는 자원 할당을 보류합니다. 시스템을 항상 safe state로 유지하면서 데드락을 회피합니다.
safe state는 모든 프로세스가 정상적으로 종료할 수 있는 상태를 말하며 safe sequence가 존재합니다. safe sequence를 통해 deadlock상태가 되지않음을 보장할 수 있습니다.
unsafe state는 deadlock이 발생할 가능성이 존재하는 상태입니다. 반드시 데드락이 발생한다는 의미는 아닙니다. deadlock avoidance는 몇 가지의 가정을 갖습니다. 프로세스 수, 자원의 종류와 수가 고정되어있어야합니다. 또, 프로세스가 요구하는 자원 및 최대 수량을 알고 있어야합니다. 프로세스는 자원을 사용후에 반드시 반납해야합니다. 이 모든 것을 안다는 것은 다소 현실적이지 않은 가정입니다.

deadlock avoidance방법 중에 대표적으로 은행원 알고리즘이라고 불리는 다익스트라 알고리즘이 있습니다. 전체 필요한 자원, 현재 가진 자원, 추가적으로 필요한 자원 수를 통해 자원을 줬다고 가정합니다. 순차적으로 시나리오를 구성해 작업이 모두 완료될 수 있는 상태가 존재하면 safe state라고 할 수 있습니다. safe state가 존재하면 자원을 빌려주고 아니라면 자원 요청을 거절합니다.  

deadlock avoidance는 항상 시스템을 감시해야하는 오버헤드가 있습니다. 또 unsafe state라고해서 반드시 데드락이 발생하지는 않는데, safe state상태여야만 자원을 빌려주기 때문에 자원의 활용도가 떨어집니다. 그리고 deadlock avoidance를 하기위한 초기 가정이 현실적이지 않은 문제가 있습니다.   
 
**Detection**  
deadlock detection은 deadlock 방지를 위한 사전작업을 하지 않습니다. 따라서 deadlock이 발생할 수 있습니다. 주기적으로 deadlock을 확인하면서 데드락이 감지된 경우 recovery가 필요합니다. avoidance와 detection의 차이점은 avoidance는 미래에 발생할 최악의 경우를 고려해서 deadlock이 발생하지 않게 해준다면 detection은 현재상태만을 고려하여 deadlock 발생시 recovery합니다.

deadlock 검출에는 RAG(resoure allocation graph)를 사용합니다. 이 그래프는 프로세스와 자원의 요청이 노드와 edge로 구성되어있습니다. 자원의 요청이 가능한 경우 edge를 제거해나가면서 주어진 모든 edge를 제거할 수 있는지 확인합니다. edge가 모두 제거되면 모든 프로세스는 자원을 할당 받을 수 있는 상태며 edge가 남아있다면 하나 이상의 프로세스가 deadlock 상태라 판단할 수 있습니다. 이 방식을 graph reduction이라고 하는데 검사에 따른 비용이 발생하며 node의 수가 증가함에 따라 더 복잡해집니다.

Deadlock Recovery는 deadlock을 검출한 뒤 해결하는 과정입니다. 데드락에 빠진 프로세스중 하나를 종료하거나 자원을 소유한 프로세스를 종료해서 데드락을 해소할 수 있습니다. 그렇다면 어떤 프로세스를 종료시킬지가 정해져야하는데 우선순위, 총 수행시간, 남은 수행시간등 cost를 고려하여 결정할 수 있습니다.
</details></br>

## 메모리 관리 기법

<details>
    <summary style="font-size : 20px;"><strong>  Q. 메모리의 계층 구조는?  </strong></summary></br>

레지스터, 캐시, 메모리, 하드 디스크 순서입니다. 보조 기억 장치와 주 기억 장치 사이의 데이터 전송 단위(1-4KB)는 block이라고 부르고, 주 기억 장치와 레지스터 사이의 데이터 전송 단위(16-64bits)는 word라고 부릅니다
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. address binding이란?  </strong></summary></br>

address binding이란 프로그램의 논리 주소를 실제 메모리의 물리 주소로 매핑하는 작업을 말합니다. address binding은 compile time, load time, run time에 실행될 수 있습니다.  
compile time binding은 프로세스가 메모리에 적재될 위치를 컴파일러가 알 수 있는 경우 컴파일 시점에서 메모리 주소를 매핑합니다.
load time binding은 메모리의 적재 위치를 컴파일 타임에 모르면, 일단 상대 주소를 생성하고 적재 시점에 시작 주소를 반영합니다.   
run time binding은 프로세스가 실행 될 때 주소를 정해줍니다. 즉, 수행이 시작된 이후에도 실행 중에 프로세스의 메모리 상의 위치를 옮길 수 있습니다. MMU(memory management unit)이라는 하드웨어의 도움을 받아 주소를 매핑합니다.  

load time binding과 run time binding의 차이는 load time binding은 메모리의 적재 시점에 메모리의 주소가 모두 매핑되야합니다. 그렇기에 오버헤드가 크고 run time binding은 프로세스가 실행중에 mapping을 진행하는 방식으로 작동됩니다.     
</details></br>


<details>
    <summary style="font-size : 20px;"><strong> Q. swapping 이란?  </strong></summary></br>

메모리에서 swap-device로 프로세스를 쫒아내는 것을 swap-out이라고 하며 swap-device에 있는 프로세스를 메모리로 불러들이는 것을 swap-in이라고 합니다. 이 과정을 swapping이라고 합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. Fragmentation에 대해 설명하시오.  </strong></summary></br>

fragmentation는 internal fragmentation와 external fragmentation로 나뉩니다. internal fragmentation은 메모리 내부의 partition의 크기가 process의 크기보다 크기 때문에 메모리의 낭비가 생기는 상황입니다. external fragmentation와 남은 메모리의 크기가 process의 크기보다 크지만 남은 메모리가 연속된 공간으로 존재하지 않기 때문에 프로세스가 메모리를 할당 받을 수 없는 상황을 말합니다.  
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. FPM과 VPM에 대해 설명하시오.</strong></summary></br>

FPM(Fixed-Partition multiprogramming)은 고정크기의 파티션으로 메모리를 분할하여 각 공간에 각 프로세스를 할당하는 방식입니다. 메모리의 관리가 편하지만 내부 단편화, 외부 단편화가 발생하여 시스템 자원이 낭비될 수 있습니다.  
VPM(Variable Partition multiprogramming)은 초기에 하나가 전체 영역이며 프로세스를 처리하는 과정에서 메모리 공간을 동적으로 분할하는 방식을 말합니다. 프로세스의 크기만큼 메모리를 분할하기 때문에 외부 단편화는 발생할 수 있으나 내부 단편화는 발생하지 않습니다. 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. VPM의 배치 전략은? </strong></summary></br>
    
VPM에 할당된 프로세스가 메모리를 반납하면 메모리 공간 내부에 비어진 파티션이 존재합니다. 다음 프로세스는 어떤 파티션으로 배치되어야할지 결정해야합니다. 

first-fit(최초 적합) 방식은 프로세스가 들어갈 수 있는 충분한 크기를 가진 첫 번째 partition을 선택합니다. 간단한 방식으로 오버헤드가 적습니다. partition의 크기와 프로세스의 크기를 고려하지 않은 방식으로 공간 활용율이 떨어질 가능성이 큽니다.

best-fit(최적 적합) 방식은 프로세스가 들어갈 수 있는 공간중 가장 작은 곳을 선택합니다. 모든 partition을 검색해야하므로 오버헤드가 크지만 크기가 큰 partition을 유지할 수 있습니다. 하지만 작은 크기의 partition이 많이 발생 합니다.

worst-fit(최악 적합) 방식은 프로세스가 들어갈 수 있는 가장 큰 partition을 선택합니다. 마찬가지로 모든 partition을 검색해야하므로 오버헤드가 크지만 작은 partition 발생을 줄일 수 있습니다. 하지만 큰 크기의 partition의 확보가 어렵습니다.

next-fit(순차 최초 적합) 방식은 최초 적합과 유사합니다. 다만 state table에서 마지막으로 탐색한 위치부터 탐색을 시작합니다. 
 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong> Q. VPM의 external fragmentation은 어떻게 해결해야하나요?   </strong></summary></br>

VPM의 external fragementation을 해소할 수 있는 방식은 coalescing hole(공간 통합)과 storage compression(메모리 압축)이 있습니다.  
coalescing hole은 인접한 두 영역을 하나의 partition으로 통합하는 방식입니다. 프로세스가 메모리를 release하고 나가면 수행할 수 있고 오버헤드가 적습니다.   
storage compression은 모든 빈 공간을 하나로 통합합니다. 프로세스 처리에 필요한 적재공간확보가 필요할 때 수행합니다. 모든 process를 재배치해야하므로 많은 시스템 자원을 소비하고 자주해줄 수 없어 일정 시간 혹은 요청이 있을 때 사용하는 방식입니다.
 
</details></br>

## 가상 메모리
<details>
    <summary style="font-size : 20px;"><strong>  Q. 가상 메모리란?   </strong></summary></br>

가상 메모리는 프로세스 전체가 메모리에 올라오지 않고도 실행하게 할 수 있는 기법으로 프로세스가 물리 메모리보다 크더라도 실행할 수 있는 장점이 있습니다. 가상 메모리는 프로세스를 연속적인 메모리공간이라고 가정하고 virtual address상에 주소를 지정합니다. 그리고 address mapping을 통해 real address로 변환해서 물리적인 메모리 주소와 mapping합니다. 사용자의 프로그램을 block 단위로 분할해서 관리하는데, 각 block에 대한 address mapping정보를 유지합니다. BMT(block map table)테이블은 address mapping 정보를 관리하는 테이블로서 커널 공간에 프로세스마다 하나의 BMT를 가집니다.
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. 가상 메모리의 address mapping 과정을 설명하시오  </strong></summary></br>

virtual address는 block number와 주소에 대한 offset정보가 담겨있습니다. 먼저, 프로세스의 bmt에 접근하고 bmt에서 block에 대한 entry를 찾습니다. 그리고 residence bit를 확인하여 residence bit가 0인 경우 swap device에서 해당 블록을 메모리로 가져옵니다. 이후 bmt를 업데이트하고 block에 대한 실제 메모리 주소를 얻어 메모리에 접근합니다. 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. paging 시스템은 무엇인가요? </strong></summary></br>

paging 시스템은 프로그램을 page라고 불리는 같은 크기의 블록으로 분할 합니다. 메모리는 page frame으로 관리되며 page와 같은 크기로서 메모리를 분할해서 사용합니다. page 시스템은 논리적인 분할이 아닌 크기에 따라 물리적으로 분할되기 때문에 따라서 내부 단편화가 발생할 가능성이 있습니다. 하지만 프로세스가 올라가거나 못올라가는 상황만 존재할 뿐 메모리가 충분한데 올라가지 못하는 상황은 발생하지 않습니다. 따라서 외부 단편화는 발생하지 않습니다. 프로그램을 논리적인 단위로 분할하는 segmentation시스템 대비 page 공유 및 보호 과정이 복잡하지만 관리가 단순하고 효율적인 특징이 있습니다.
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. paging 시스템의 address mapping 방식은?</strong></summary></br>

해당 프로세스의 PMT(page map table)가 저장된 주소로 이동하여 page number로 entry를 찾습니다. 찾은 entry에서 residence bit를 검사해서 0인 경우 swap device로 부터 page를 메모리에 적재하는 작업이 진행됩니다. 이를 page fault라고 합니다. 적재가 완료되면 PMT를 업데이트하고 page frame 번호를 확인합니다. page frame번호와 주소 값의 offset으로 실제 주소에 접근합니다.

</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. paging 시스템의 메모리 관리 방법은?</strong></summary></br>

page와 같은 크기로 메모리를 미리 분할하여 관리합니다. FPM방식과 유사합니다. frame table에는 page frame당 하나의 entry가 존재하고 allocatation 여부, PID, page frame number, 비어있는 entry정보등의 정보가 담겨있습니다.  
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>   Q. paging 시스템의 공유자원/보안 문제에 대해 설명하시오</strong></summary></br>

non-continous allocation적인 특징으로 여러 프로세스가 특정 page를 공유할 수 있습니다. 공유 가능한 page로는 1. procedure page, 2. data page가 있고 read-write한 데이터의 경우 concurrency제어 기법 관리하에 가능합니다. procedure page sharing에 따른 문제도 존재합니다. 각각의 PMT에서 같은 메모리 주소를 가르키는 page의 명칭이 다를 경우 branch에서 실제 주소와 다른 곳으로 갈 수 있습니다. 그렇기에 share page에 대한 정보를 PMT의 같은 entry에 저장하도록 해야합니다.
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. segmentation 시스템이란?</strong></summary></br>

프로그램을 논리적 block으로 분할하는 시스템(segment). block의 크기가 서로 다를 수 있습니다. 예)stack, heap, main procedure, shared lib, etc  
 segmentation 시스템은 VPM과 유사하게 메모리를 관리하며 미리 메모리를 분할하지않습니다. address mapping및 메모리 관리에대한 오버헤드가 크지만 내부 단편화가 발생하지 않고 segment의 공유나 
 protection이 용이합니다.
</details></br>


<details>
    <summary style="font-size : 20px;"><strong>  Q. segmentation 시스템의 address mapping 방식은?</strong></summary></br>

프로세스의 SMT(segement map table)로 접근하여 segment number에 대한 엔트리를 찾습니다. 엔트리에서 residence bit를 확인하여 0인경우 segment fault가 발생한 상황으로 swap device로부터
segment를 메모리로 적재합니다. 이후 SMT를 갱신합니다. 만약 offset이 segment길이보다 큰 경우 segment overflow exception 처리 모듈을 호출합니다. protection bit를 확인하고 허가되지 않은 연산을 수행하려는 경우 segment protection exception을 호출합니다. 이후 실제 주소를 계산해 메모리로 접근합니다.

</details></br>


<details>
    <summary style="font-size : 20px;"><strong>   Q. segmentation 시스템의 메모리 관리 방법은?</strong></summary></br>

VPM과 유사하게 segment의 크기에 맞춰 분할 후 적재합니다. partition table에서 각 파티션과 크기, segment number, PID등에 대한 정보를 관리합니다. 
</details></br>

</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. Page reference string이란?</strong></summary></br>

프로세스의 수행 중 참조한 페이지 번호 순서입니다. 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. page fault란?</strong></summary></br>

cpu가 메인 메모리에서 page를 확인할 때 page가 존재하지 않을 경우 context switcing이 발생하며 작업이 중단됩니다. 그 후 swap device에서 필요한 page를 메모리의 page frame으로 올린다. 페이지가 로드되면 PMT를 업데이트하고 CPU는 다시 작업을 진행한다. page fault는 context switching이 발생하기 때문에 오버헤드가 큽니다. 시스템 성능을 향상하기위해서는 page fault rate를 최소화하는 설계를 해야합니다.
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. 가상메모리를 시스템 성능 최적화를 위한 방법은 무엇이있나요?</strong></summary></br>

**Allocation strategies**   
각 프로세스에게 메모리를 얼마만큼 줄 것인지 정하는 전략입니다.  
fixed allocation(고정 할당) : 프로세스의 실행 동안 고정된 크기의 메모리 할당 (프로세스에게 page frame의 수를 고정해서 준다.)  
Variable allocation(가변 할당) :프로세스의 실행 동안 할당하는 메모리의 크기가 유동적 (할당 받은 page frame수가 변한다.)   
프로세스 실행에 필요한 메모리양을 예측해서 적절히 메모리를 분배해야합니다. 너무 큰 메모리를 할당하면 메모리가 낭비되고 너무 적은 메모리를 할당하면 page fault rate가 증가하여 시스템 성능이 저하됩니다.   
 

**Fetch strategies**   
특정 page를 메모리에 언제 적재할 것인지 정하는 전략입니다.   
demand fetch(demand paging) : 프로세스가 참조하는 페이지들만 적재합니다. page fault overhead가 발생합니다.    
anticipatory fetch (pre-paging) : 참조될 가능이 높은 page 예측하여 가까운 미래에 참조될 가능성이 높은 page를 미리 적재합니다. 예측 성공시, page fault overhead가 없습니다. prediction overhead (kernel의 개입)이 존재하고, hit ratio(예상이 얼마나 맞는지)에 민감합니다.     
실제 대부분의 시스템은 demand fetch 기법 사용합니다. 일반적으로  준수한 성능을 보여주고 anticipatory fetch방식은  prediction overhead가 있고 잘못된 예측 시 자원 낭비가 큽니다.     

**Placement strategies**      
page/segment를 어디에 적재할 것인지 정하는 전략입니다.  
paging system은 크기가 일정하기 때문에 불필요합니다.  
segmentation system에서의 배치 기법 : first-fit, best-fit, worst-fit, next-fit등등  
 
**Replacement strategies**  
빈 page frame이 없는 경우 새로운 page를 어떤 page와 교체 할지 정하는 전략입니다. fixed allocation을 위한 교체 기법과 variable allocation을 위한 교체 기법으로 나뉩니다.  
  
**Cleaning strategies**  
변경된 page를 언제 write-back 할 것인지 정하는 전략입니다.  
demand cleaning : 해당 page에 메모리에서 내려올 때 write-back합니다.   
anticipatory cleaning (pre-cleaning) : 더이상 변경될 가능성이 없다고 판단 할 때, 미리 write-back합니다. page교체시 발생하는 write-back 시간을 절약합니다. 만약, write-back이후, page 내용이 수정되면, overhead가 발생합니다.  
실제 대부분 시스템은 demand cleaning 기법을 사용합니다. 일반적으로 준수한 성능을 보여주고 anticipatory cleaning은 prediction overhead가 존재하고 잘못된 예측 시 자원 낭비가 큽니다.  
 
</details></br>

<details>
    <summary style="font-size : 20px;"><strong>  Q. Page 교체 알고리즘에 대해서 설명해주세요</strong></summary></br>

page 교체 알고리즘은 정해진 페이지 프레임 수 만큼 할당하는 Fixed Allocation과 페이지 프레임 수를 지정하지 않고 할당하는 Variable Allocation에 따라 나뉩니다. 

**Fixed Allocation**

Min Algorithm (OPT algorithm)  
page fault frequency를 최소화 시키는 알고리즘으로 앞으로 가장 오랫동안 참조되지 않을 page 교체합니다. page reference string을 미리 알고 있어야하기 때문에 실현 불가능한 방법입니다(페이지가 언제 참조될지 알 수 없음) 하지만, 최적의 알고리즘인 만큼 다른 교체 알고리즘의 성능 평가 도구로 사용 됩니다.  

Random Algorithm  
무작위로 교체할 page선택합니다. 낮은 오버헤드와 policy가 없습니다. 랜덤인 해당 알고리즘과 비교를 통해 성능 평가의 지표로도 사용할 수 있습니다.   

FIFO Algorithm  
First In First Out으로 가장 오래된 page를 교체합니다. page가 적재 된 시간을 기억하고 있어야 합니다. 자주 사용되는 page가 교체 될 가능성이 있습니다(Locality에 대한 고려가 없음)
FIFO anomaly(Belady's anomaly) :FIFO알고리즘의 경우 더 많은 page frame을 할당 받음에도 불구하고 page fault가 증가하는 경우가 있습니다.  

LRU (Least Recently Used) Algorithm  
가장 오랫동안 참조되지 않은 page를 교체 합니다(locality) page 참조 시 마다 시간을 기록해야하므로 Overhead가 발생하지만 간소화된 정보 수집으로 해소 가능하다(정확한 시간 대신, 순서만 기록) Loop 실행에 필요한 크기보다 작은 수의 page frame이 할당 된 경우, page fault수가 급격히 증가합니다(allocation 기법에서 해결해야함) Locality에 기반을 둔 교체 기법으로 MIN algorithm에 근접한 성능을 보여줍니다. 실제로 가장 많이 활용되는 기법이다.

LFU(Least Frequenctly Used) Algorithm   
가장 참조 횟수가 적은 page를 교체합니다. page 참조 시 마다, 참조 횟수를 누적 시켜야합니다. LRU처럼 Locality 활용하지만 LRU대비 적은 overhead가 발생한다. 하지만, 최근 적재된 참조될 가능성이 높은 page가 교체 될 가능성이 있습니다. 

**Variable Allocation**  

Working Set Algorithm
일정 시간동안 참조된 페이지의 집합을 working set이라하며 working set에 있는 페이지를 메모리에 유지합니다. window size는 이지만 working set에 담긴 페이지의 수는 고정되지 않으므로
 memory allocation은 가변적입니다. window size가 성능을 결정하는 중요한 요소입니다. 적재되는 page가 없어도 반납하는 page가 존재할 수 있으며 적재되는 page가 있어도 반납되는 page가 없을 수 있습니다. 지속해서 working set을 관찰해야하는 오버헤드가 있습니다.
 
Page Fault Frequency(PFF) algorithm
page fault 발생 빈도에따라 Residence set의 크기를 조절하는 알고리즘입니다. 이전 page fault와 현재 page fault 사이에 걸린 시간을 계산하여 기준치 이상이면 page frame 크기를 줄이고 기준치 미만이면 page frame 크기를 늘립니다. Resident set 갱신 및 메모리 할당은 page fault가 발생시에만 수행합니다. 그러므로 항상 working set을 관찰해야하는 WS대비 overhead가 적습니다.

Variable MIN algorithm(OPT algorithm) 
Variable allocation 기반 교체 기법 중  optimal algorithm입니다. page reference string을  미리 알고 있어야 하므로 실현 불가능한 기법(Unrealizable)입니다. 일정 시간내에 page가 다시 참조되는지 확인해서 교체할 페이지를 선택합니다.
 
</details></br>


